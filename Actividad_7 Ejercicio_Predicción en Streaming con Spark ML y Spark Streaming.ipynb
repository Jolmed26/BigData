{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ba9a31f",
      "metadata": {
        "id": "9ba9a31f"
      },
      "source": [
        "# Predicción en Streaming con Spark ML y Spark Streaming"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80ea30cb",
      "metadata": {
        "id": "80ea30cb"
      },
      "source": [
        "En este notebook vamos a entrenar un modelo de clasificación para predecir la probabilidad de un paciente de sufrir un ataque al corazón"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6318a507",
      "metadata": {
        "id": "6318a507"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4878544d",
      "metadata": {
        "id": "4878544d"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import OneHotEncoder\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "56cecab8",
      "metadata": {
        "id": "56cecab8"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('UCI Heart disease').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "afe3c31c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afe3c31c",
        "outputId": "4a4b3dbc-f101-4228-f971-74ef71097d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "|age|sex| cp|trestbps|chol|fbs|restecg|thalach|exang|oldpeak|slope| ca|thal|target|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "| 63|  1|  3|     145| 233|  1|      0|    150|    0|    2.3|    0|  0|   1|     1|\n",
            "| 37|  1|  2|     130| 250|  0|      1|    187|    0|    3.5|    0|  0|   2|     1|\n",
            "| 41|  0|  1|     130| 204|  0|      0|    172|    0|    1.4|    2|  0|   2|     1|\n",
            "+---+---+---+--------+----+---+-------+-------+-----+-------+-----+---+----+------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "heart = spark.read.csv('/content/heart.csv',\n",
        "                       inferSchema = True,\n",
        "                       header = True)\n",
        "heart.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "e8216cc4",
      "metadata": {
        "id": "e8216cc4"
      },
      "outputs": [],
      "source": [
        "schema = StructType( \\\n",
        "                     [StructField(\"age\", LongType(),True), \\\n",
        "                      StructField(\"sex\", LongType(), True), \\\n",
        "                      StructField(\"cp\", LongType(), True), \\\n",
        "                      StructField('trestbps', LongType(), True), \\\n",
        "                      StructField(\"chol\", LongType(), True), \\\n",
        "                      StructField(\"fbs\", LongType(), True), \\\n",
        "                      StructField(\"restecg\", LongType(), True), \\\n",
        "                      StructField(\"thalach\", LongType(), True),\\\n",
        "                      StructField(\"exang\", LongType(), True), \\\n",
        "                      StructField(\"oldpeak\", DoubleType(), True), \\\n",
        "                      StructField(\"slope\", LongType(),True), \\\n",
        "                      StructField(\"ca\", LongType(), True), \\\n",
        "                      StructField(\"thal\", LongType(), True), \\\n",
        "                      StructField(\"target\", LongType(), True), \\\n",
        "                        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "28d8812f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28d8812f",
        "outputId": "8cafd4a2-159c-4cad-9471-dcdfb4c54b54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- sex: integer (nullable = true)\n",
            " |-- cp: integer (nullable = true)\n",
            " |-- trestbps: integer (nullable = true)\n",
            " |-- chol: integer (nullable = true)\n",
            " |-- fbs: integer (nullable = true)\n",
            " |-- restecg: integer (nullable = true)\n",
            " |-- thalach: integer (nullable = true)\n",
            " |-- exang: integer (nullable = true)\n",
            " |-- oldpeak: double (nullable = true)\n",
            " |-- slope: integer (nullable = true)\n",
            " |-- ca: integer (nullable = true)\n",
            " |-- thal: integer (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.types import StructType,StructField,LongType, StringType,DoubleType,TimestampType\n",
        "\n",
        "df = heart.withColumnRenamed(\"target\",\"label\")\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1b2c3b4b",
      "metadata": {
        "id": "1b2c3b4b"
      },
      "outputs": [],
      "source": [
        "testDF, trainDF = df.randomSplit([0.3, 0.7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9ea2376e",
      "metadata": {
        "id": "9ea2376e"
      },
      "outputs": [],
      "source": [
        "# Creamos el modelo de regresión lineal\n",
        "lr = LogisticRegression(maxIter=10, regParam= 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4007600c",
      "metadata": {
        "id": "4007600c"
      },
      "outputs": [],
      "source": [
        "# Creamos el hot enconder\n",
        "ohe = OneHotEncoder(inputCols = ['sex', 'cp', 'fbs', 'restecg', 'slope',\n",
        "                                 'exang', 'ca', 'thal'],\n",
        "                    outputCols=['sex_ohe', 'cp_ohe', 'fbs_ohe',\n",
        "                                'restecg_ohe', 'slp_ohe', 'exng_ohe',\n",
        "                                'caa_ohe', 'thall_ohe'])\n",
        "\n",
        "# Lista de Inputs list para escalación\n",
        "inputs = ['age','trestbps','chol','thalach','oldpeak']\n",
        "\n",
        "# Escalamos los Inputs\n",
        "assembler1 = VectorAssembler(inputCols=inputs, outputCol=\"features_scaled1\")\n",
        "scaler = MinMaxScaler(inputCol=\"features_scaled1\", outputCol=\"features_scaled\")\n",
        "\n",
        "# Creamos un segundo assambles para el encoder por columna.\n",
        "assembler2 = VectorAssembler(inputCols=['sex_ohe', 'cp_ohe',\n",
        "                                        'fbs_ohe', 'restecg_ohe',\n",
        "                                        'slp_ohe', 'exng_ohe', 'caa_ohe',\n",
        "                                        'thall_ohe','features_scaled'],\n",
        "                             outputCol=\"features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "247fdb95",
      "metadata": {
        "id": "247fdb95"
      },
      "outputs": [],
      "source": [
        "# Creamos la lista de stages\n",
        "myStages = [assembler1, scaler, ohe, assembler2,lr]\n",
        "\n",
        "# Set up de los pipelines\n",
        "pipeline = Pipeline(stages= myStages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8ab63f90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ab63f90",
        "outputId": "585dcc19-f2b6-4963-82ef-fc274d3afe4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+----------+\n",
            "|label|         probability|prediction|\n",
            "+-----+--------------------+----------+\n",
            "|    1|[0.02515687743517...|       1.0|\n",
            "|    1|[0.05536930420429...|       1.0|\n",
            "|    0|[0.88743407623801...|       0.0|\n",
            "|    1|[0.04848075370175...|       1.0|\n",
            "|    1|[0.00563778993093...|       1.0|\n",
            "|    1|[0.05397991136446...|       1.0|\n",
            "|    1|[0.05397991136446...|       1.0|\n",
            "|    0|[0.66759380307695...|       0.0|\n",
            "|    1|[0.03549035603854...|       1.0|\n",
            "|    0|[0.72461695624972...|       0.0|\n",
            "|    1|[0.02977025491517...|       1.0|\n",
            "|    1|[0.07690074513393...|       1.0|\n",
            "|    1|[0.02211384105073...|       1.0|\n",
            "|    1|[0.03738110239609...|       1.0|\n",
            "|    1|[0.01118905216260...|       1.0|\n",
            "|    0|[0.24448631285092...|       1.0|\n",
            "|    1|[0.05569670760886...|       1.0|\n",
            "|    1|[0.03647372276783...|       1.0|\n",
            "|    1|[0.28994791812000...|       1.0|\n",
            "|    1|[0.17150808593248...|       1.0|\n",
            "+-----+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Hacemos el fit de los modelo usando los datos de entrenamiento.\n",
        "pModel = pipeline.fit(trainDF)\n",
        "\n",
        "# Transformamos los datos\n",
        "trainingPred = pModel.transform(trainDF)\n",
        "\n",
        "# # Seleccionamos label, probability and predictions\n",
        "trainingPred.select('label','probability','prediction').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c2077daa",
      "metadata": {
        "id": "c2077daa",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#Guardamos los pipelines\n",
        "pModel.save(\"/Pipelines\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3391605d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3391605d",
        "outputId": "0dfb97f0-9d1e-49ef-bd66-44121e66b771"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PipelineModel_b4ba52657328"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml import PipelineModel\n",
        "\n",
        "#Cargamos los pipelines\n",
        "pModel = PipelineModel.load(\"/Pipelines\")\n",
        "\n",
        "pModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "67wcY4R4tZQ3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67wcY4R4tZQ3",
        "outputId": "d5747d38-23b4-4840-a5fb-62f1b235d574"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+----------+\n",
            "|label|         probability|prediction|\n",
            "+-----+--------------------+----------+\n",
            "|    1|[0.02515687743517...|       1.0|\n",
            "|    1|[0.05536930420429...|       1.0|\n",
            "|    0|[0.88743407623801...|       0.0|\n",
            "|    1|[0.04848075370175...|       1.0|\n",
            "|    1|[0.00563778993093...|       1.0|\n",
            "|    1|[0.05397991136446...|       1.0|\n",
            "|    1|[0.05397991136446...|       1.0|\n",
            "|    0|[0.66759380307695...|       0.0|\n",
            "|    1|[0.03549035603854...|       1.0|\n",
            "|    0|[0.72461695624972...|       0.0|\n",
            "|    1|[0.02977025491517...|       1.0|\n",
            "|    1|[0.07690074513393...|       1.0|\n",
            "|    1|[0.02211384105073...|       1.0|\n",
            "|    1|[0.03738110239609...|       1.0|\n",
            "|    1|[0.01118905216260...|       1.0|\n",
            "|    0|[0.24448631285092...|       1.0|\n",
            "|    1|[0.05569670760886...|       1.0|\n",
            "|    1|[0.03647372276783...|       1.0|\n",
            "|    1|[0.28994791812000...|       1.0|\n",
            "|    1|[0.17150808593248...|       1.0|\n",
            "+-----+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Comprueba que el pipeline anterior funciona correctamente. Para ello realiza una prediccion sobre el conjunto de\n",
        "## datos de trainDF y muestra la prediccion\n",
        "\n",
        "# Transformamos los datos.\n",
        "trainingPred = pModel.transform(trainDF)\n",
        "\n",
        "# # We select the actual label, probability and predictions\n",
        "selected_predictions = trainingPred.select('label','probability','prediction')\n",
        "\n",
        "selected_predictions.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "7g22gEvBci9I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g22gEvBci9I",
        "outputId": "17c16a6d-9f7f-4d55-b65d-cef20331093e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['age',\n",
              " 'sex',\n",
              " 'cp',\n",
              " 'trestbps',\n",
              " 'chol',\n",
              " 'fbs',\n",
              " 'restecg',\n",
              " 'thalach',\n",
              " 'exang',\n",
              " 'oldpeak',\n",
              " 'slope',\n",
              " 'ca',\n",
              " 'thal',\n",
              " 'label',\n",
              " 'features_scaled1',\n",
              " 'features_scaled',\n",
              " 'sex_ohe',\n",
              " 'cp_ohe',\n",
              " 'fbs_ohe',\n",
              " 'restecg_ohe',\n",
              " 'slp_ohe',\n",
              " 'exng_ohe',\n",
              " 'caa_ohe',\n",
              " 'thall_ohe',\n",
              " 'features',\n",
              " 'rawPrediction',\n",
              " 'probability',\n",
              " 'prediction']"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainingPred.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "uozV2VXbuj0t",
      "metadata": {
        "id": "uozV2VXbuj0t"
      },
      "outputs": [],
      "source": [
        "testData = testDF.repartition(10)\n",
        "\n",
        "\n",
        "testData.write.format(\"CSV\").option(\"header\",True).mode(\"overwrite\").save(\"/heart_streaming/\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2K6vogXuuHj",
      "metadata": {
        "id": "e2K6vogXuuHj"
      },
      "source": [
        "## Creando predicciones en Streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "e-9gHMYouvLb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-9gHMYouvLb",
        "outputId": "c4368d1a-d6ff-42a0-cea6-3d4e8674544d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[age: bigint, sex: bigint, cp: bigint, trestbps: bigint, chol: bigint, fbs: bigint, restecg: bigint, thalach: bigint, exang: bigint, oldpeak: double, slope: bigint, ca: bigint, thal: bigint, label: bigint]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Utiliza los csv guardados en data/heart_streaming para simular un proceso de datos en streaming.\n",
        "## Para ello, utiliza la funcion de spark.readStream\n",
        "## En la configuración pon: que se importe un archivo por ejecucion\n",
        "## que se renombre la variable de \"output\"a \"label\"\n",
        "## Llama a este proceso con el nombre sourceStream\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "sourceStream = (\n",
        "    spark.readStream.format(\"csv\")\n",
        "    .option(\"header\",\"True\")\n",
        "    .schema(schema)\n",
        "    .option(\"ignoreLeadingWhiteSpace\",True)\n",
        "    .option(\"mode\",\"dropMalformed\")\n",
        "    .option(\"maxFilesPerTrigger\",1)\n",
        "    .load(\"/heart_streaming/\")\n",
        "    .withColumnRenamed(\"target\",\"label\")\n",
        ")\n",
        "\n",
        "sourceStream\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "zEh4ODVRTK05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEh4ODVRTK05",
        "outputId": "43e119fd-f82c-410d-cc2e-6f21731056bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sourceStream.isStreaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "3eGwH8rQ-XRA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eGwH8rQ-XRA",
        "outputId": "76f37d96-295b-4bc5-a2de-93434770d4cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- age: long (nullable = true)\n",
            " |-- sex: long (nullable = true)\n",
            " |-- cp: long (nullable = true)\n",
            " |-- trestbps: long (nullable = true)\n",
            " |-- chol: long (nullable = true)\n",
            " |-- fbs: long (nullable = true)\n",
            " |-- restecg: long (nullable = true)\n",
            " |-- thalach: long (nullable = true)\n",
            " |-- exang: long (nullable = true)\n",
            " |-- oldpeak: double (nullable = true)\n",
            " |-- slope: long (nullable = true)\n",
            " |-- ca: long (nullable = true)\n",
            " |-- thal: long (nullable = true)\n",
            " |-- label: long (nullable = true)\n",
            " |-- features_scaled1: vector (nullable = true)\n",
            " |-- features_scaled: vector (nullable = true)\n",
            " |-- sex_ohe: vector (nullable = true)\n",
            " |-- cp_ohe: vector (nullable = true)\n",
            " |-- fbs_ohe: vector (nullable = true)\n",
            " |-- restecg_ohe: vector (nullable = true)\n",
            " |-- slp_ohe: vector (nullable = true)\n",
            " |-- exng_ohe: vector (nullable = true)\n",
            " |-- caa_ohe: vector (nullable = true)\n",
            " |-- thall_ohe: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Utiliza el pipeline \"pModel\" para realizar predicciones utilizando los datos en streaming de \"sourceStream\"\n",
        "## De la predicción selecciona las variables label, probability, prediction.\n",
        "## Llama a este proceso con el nombre de \"prediction1\"\n",
        "\n",
        "prediction1 = pModel.transform(sourceStream)\n",
        "\n",
        "prediction1.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "ZE17i9cBcLQJ",
      "metadata": {
        "id": "ZE17i9cBcLQJ"
      },
      "outputs": [],
      "source": [
        "prediction1 = prediction1.select(\"label\", \"probability\", \"prediction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "fsOgMY8AOAGt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "fsOgMY8AOAGt",
        "outputId": "987f252e-97cc-46a7-f5e3-6ea6ac7077e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[label: bigint, probability: vector, prediction: double]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(prediction1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "atIgaVZ0OOGT",
      "metadata": {
        "id": "atIgaVZ0OOGT"
      },
      "source": [
        "#### Mostrando las predicciones en consola"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "zLnZaCxR_HQK",
      "metadata": {
        "id": "zLnZaCxR_HQK"
      },
      "outputs": [],
      "source": [
        "## Obten las predicciones sobre los datos en streaming, para ello utiliza prediction1.writeStream. En las opciones de\n",
        "## configuracion pon: \"format\" igual a \"console\"\n",
        "## en .trigger igual (once=True),\n",
        "## y permite que el proceso espere hasta que se complete con .awaitTermination()\n",
        "\n",
        "# Define the streaming query\n",
        "query = (\n",
        "    prediction1\n",
        "    .writeStream\n",
        "    .outputMode(\"append\")\n",
        "    .format(\"console\")  # You can change the output format as needed\n",
        "    .trigger(once = True)\n",
        "    .queryName(\"prediction1\")\n",
        "    .start()\n",
        ")\n",
        "\n",
        "# Await termination of the streaming query\n",
        "query.awaitTermination()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IJV5A2QvO3BA",
      "metadata": {
        "id": "IJV5A2QvO3BA"
      },
      "source": [
        "#### Guardando las perdicciones en Memoria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "s88tqHADOwdn",
      "metadata": {
        "id": "s88tqHADOwdn"
      },
      "outputs": [],
      "source": [
        "## Obten las predicciones sobre los datos en streaming, para ello utiliza prediction1.writeStream.\n",
        "## En las opciones de configuracion pon: que los resultados se guarden en memoria,\n",
        "## que el .outputMode sea \"append\"\n",
        "## que el nombre de la query \"queryName\" sea \"prediction4\"\n",
        "\n",
        "query = (\n",
        "    prediction1\n",
        "    .writeStream\n",
        "    .outputMode(\"append\")\n",
        "    .format(\"memory\")  # You can change the output format as needed\n",
        "    .trigger(once = True)\n",
        "    .queryName(\"prediction4\")\n",
        "    .start()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "UAGFqIruO-An",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAGFqIruO-An",
        "outputId": "efeff9b9-fb66-4779-bd9c-c465960ccc31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+----------+\n",
            "|label|         probability|prediction|\n",
            "+-----+--------------------+----------+\n",
            "|    1|[0.46307504459163...|       1.0|\n",
            "|    1|[0.04349641430887...|       1.0|\n",
            "|    1|[0.07716164567849...|       1.0|\n",
            "|    0|[0.90005706585809...|       0.0|\n",
            "|    0|[0.75633699209214...|       0.0|\n",
            "|    1|[0.03854801767868...|       1.0|\n",
            "|    1|[0.08990835082386...|       1.0|\n",
            "|    0|[0.83507859969069...|       0.0|\n",
            "|    0|[0.9803939380043,...|       0.0|\n",
            "|    0|[0.97798364164624...|       0.0|\n",
            "+-----+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+-----+--------------------+----------+\n",
            "|label|         probability|prediction|\n",
            "+-----+--------------------+----------+\n",
            "|    1|[0.46307504459163...|       1.0|\n",
            "|    1|[0.04349641430887...|       1.0|\n",
            "|    1|[0.07716164567849...|       1.0|\n",
            "|    0|[0.90005706585809...|       0.0|\n",
            "|    0|[0.75633699209214...|       0.0|\n",
            "|    1|[0.03854801767868...|       1.0|\n",
            "|    1|[0.08990835082386...|       1.0|\n",
            "|    0|[0.83507859969069...|       0.0|\n",
            "|    0|[0.9803939380043,...|       0.0|\n",
            "|    0|[0.97798364164624...|       0.0|\n",
            "+-----+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DataFrame[label: bigint, probability: vector, prediction: double]"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for x in range(2):\n",
        "    df = spark.sql(\n",
        "        \"SELECT * FROM prediction4\")\n",
        "    df.show(10)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "84zQ-iCVPBHs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84zQ-iCVPBHs",
        "outputId": "354ab6d4-1a74-41c9-8d13-1284602afeb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Valida que el proceso de streaming está activo y después muestra el estado\n",
        "sourceStream.isStreaming\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
